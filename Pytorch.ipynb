{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pytorch Crash Course",
   "id": "d4b1c432bf83343c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quick Tips for installing Pytorch\n",
    "You need the CUDA Toolkit and an Nvidia GPU.\n",
    "\n",
    "Type\n",
    "```\n",
    "nvcc --version\n",
    "```\n",
    "into your console to figure out what CUDA version you have.\n",
    "\n",
    "If you don't get a return on your own computer, you might need to install the [CUDA Toolkit](https://developer.nvidia.com/cuda/toolkit).\n",
    "###### _If you are on a remote computer, you probably can't do that on your own. Talk to an admin instead._\n",
    "\n",
    "If everything is alright the return should look roughly like this:\n",
    "```\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2024 NVIDIA Corporation\n",
    "Built on Wed_Aug_14_10:26:51_Pacific_Daylight_Time_2024\n",
    "Cuda compilation tools, release 12.6, V12.6.68\n",
    "Build cuda_12.6.r12.6/compiler.34714021_0\n",
    "```\n",
    "(I have CUDA 12.6 on the machine I ran the command)\n",
    "\n",
    "Now you can go to [pytorch's official website](pytroch.org) to download pytorch for the correct CUDA version.\n",
    "\n",
    "Pytorch seems to be okay at dealing with CUDA version mismatches, I have seen newer versions of pytorch run fine with older CUDA versions. __DON'T QUOTE ME ON THIS THOUGH__\n",
    "\n",
    "Pytorch also offers [old versions](https://pytorch.org/get-started/previous-versions/) for download, which work with older CUDA versions.\n",
    "\n"
   ],
   "id": "9159a1dd2c6dca9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why use GPUs for Machine Learning?\n",
    "\n",
    "#### A Demo:\n",
    "Let's fit a CNN to CIFAR10.\n",
    "(_This code is shamelessly copied from an exercise in Prof. Jain's FMI course from last year_)"
   ],
   "id": "4cdc649c457ebf50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:27:40.528137Z",
     "start_time": "2026-01-15T16:27:38.796042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "in_channels   = 3\n",
    "num_classes   = 10\n",
    "num_workers   = 8\n",
    "batch_size    = 256 #this is pretty large for the actual model we use here, but not unreasonable in other usecases\n",
    "num_epochs    = 15\n",
    "learning_rate = 0.005"
   ],
   "id": "93eeda98c1fbfdb8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:27:42.374259Z",
     "start_time": "2026-01-15T16:27:41.125005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_data = datasets.CIFAR10(root='data', train=True, transform=transform,download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ],
   "id": "6cc54032965b6ca2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana_admin\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:27:44.624409Z",
     "start_time": "2026-01-15T16:27:44.621735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 5 * 5, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "b67ea269f184059a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        z = model(X)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "e9ac4e5267f1e9b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        z = model(X)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "d1cb456a09bac34c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Wow, the Code that runs almost a minute faster on my GPU (And it will run even faster after we have optimized it later). How can that be?\n",
    "\n",
    "Long story short: Forward- and backward-passes (Inference and Training) require massive amounts of vector/matrix (tensor) operations, which are highly parallelizable. GPUs (Graphics Processing Units) are built to solve these kinds of highly parallel operations to render pretty computer graphics, so they are also good at neural networks by accident. Datacenter GPUs nowadays are often purpose built for ML tasks, so they are even better.\n",
    "\n",
    "If you do projects on your home computer and have a decent gaming GPU, then you can probably use it for ML."
   ],
   "id": "80f2302998de3ebc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Okay but how do I PyTorch?\n",
    "\n",
    "#### Online Resources\n",
    "\n",
    "### You already know a lot of the syntax if you know Numpy\n",
    "\n"
   ],
   "id": "5700a9e270521bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4402eadc796d3709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### You probably want to use nn.Module\n",
    "\n",
    "### Having your data stored in memory can be a good or a bad idea"
   ],
   "id": "dd1249eaeadc1126"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:27:52.303367Z",
     "start_time": "2026-01-15T16:27:52.300922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(device):\n",
    "    train_data_raw = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "    train_x = torch.tensor(train_data_raw.data, device=device, dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_data_raw.targets, device=device)\n",
    "    norm = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    train_x = norm(torch.transpose(train_x,-1,-3))\n",
    "    return (train_x, train_y)"
   ],
   "id": "f1e9377628ebd2d2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:28:00.958699Z",
     "start_time": "2026-01-15T16:27:53.473072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "X,y = get_data(device)\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        z = model(X[i:i + batch_size])\n",
    "        loss = F.cross_entropy(z, y[i:i + batch_size])\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "dc35a2cd4fb7c338",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## How to write Pytorch Code that isn't (too) bad\n",
    "\n",
    "This is a guide to avoiding some common pitfalls, not to writing the fastest code possible (you probably wouldn't have time for that anyway).\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "- Compute is an expensive shared resource.\n",
    "- Wasting compute means literally just creating entropy (CLIMATE CHANGE IS A THING).\n",
    "- Other people also have projects they want to do.\n",
    "\n",
    "#### Some Online Guides that go more in-depth"
   ],
   "id": "41be8babb141ec4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Enable Tensor Cores (if applicable)\n",
    "\n",
    "Your GPU might nor support this. Most libraries that implements models (e.g. transformers etc.) will either do this by default or let you enable it through them."
   ],
   "id": "f224c2330d59cdcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:28:06.231986Z",
     "start_time": "2026-01-15T16:28:06.229334Z"
    }
   },
   "cell_type": "code",
   "source": "torch.set_float32_matmul_precision('high')",
   "id": "b6ef2342b0119ebc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "WHAT IS A TENSOR CORE\n",
    "\n",
    "\n",
    "### torch.compile is really neat\n",
    "\n",
    "You might need to install Triton though. It can usually be installed like any python package. [Windows version](https://github.com/woct0rdho/triton-windows) also exists now.\n"
   ],
   "id": "5165ac05db384678"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:33:49.047446Z",
     "start_time": "2026-01-15T16:33:34.757116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "num_epochs = 150\n",
    "\n",
    "X,y = get_data(device)\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "TORCH_LOGS=\"graph_breaks\"\n",
    "\n",
    "def train(model, optimizer, x, y):\n",
    "        z = model(x)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train = torch.compile(train)\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        train(model, optimizer, X[i:i + batch_size], y[i:i + batch_size])\n"
   ],
   "id": "c407e978aa672452",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana_admin\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n",
      " 18%|█▊        | 27/150 [00:13<01:01,  2.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, num_epochs + \u001B[32m1\u001B[39m)):\n\u001B[32m     24\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, X.size(\u001B[32m0\u001B[39m), batch_size):\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m         \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m:\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:832\u001B[39m, in \u001B[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    829\u001B[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001B[32m    831\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m832\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    833\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m Unsupported \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    834\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m config.verbose:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, optimizer, x, y)\u001B[39m\n\u001B[32m     14\u001B[39m z = model(x)\n\u001B[32m     15\u001B[39m loss = F.cross_entropy(z, y)\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m optimizer.zero_grad(set_to_none=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     18\u001B[39m loss.backward()\n\u001B[32m     19\u001B[39m optimizer.step()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mtorch_dynamo_resume_in_train_at_17\u001B[39m\u001B[34m(__nested_resume_fns, __nested_frame_values, ___stack0, optimizer, loss)\u001B[39m\n\u001B[32m     15\u001B[39m loss = F.cross_entropy(z, y)\n\u001B[32m     17\u001B[39m optimizer.zero_grad(set_to_none=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m optimizer.step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for inference you can compile you model, for training it's best practice to compile a train function instead\n",
    "\n",
    "reduce overhead arg can help with small models/batches (try it out in each usecase)"
   ],
   "id": "ca443b9b8f7ffb33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### The CPU-GPU Bottleneck\n",
    "\n"
   ],
   "id": "566a46c0efe9bf22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T16:32:16.491957Z",
     "start_time": "2026-01-15T16:31:49.395472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "X,y = get_data(device)\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        z = model(X[i:i + batch_size])\n",
    "        a = int(X[0][0][0][0])\n",
    "        loss = F.cross_entropy(z, y[i:i + batch_size])\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "53596af2e22971ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana_admin\\PycharmProjects\\PresentationHPCforStudents\\.venv\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n",
      " 17%|█▋        | 26/150 [00:26<02:05,  1.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m0\u001B[39m, X.size(\u001B[32m0\u001B[39m), batch_size):\n\u001B[32m     12\u001B[39m     z = model(X[i:i + batch_size])\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     a = \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m     loss = F.cross_entropy(z, y[i:i + batch_size])\n\u001B[32m     16\u001B[39m     optimizer.zero_grad(set_to_none=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Views and Copies\n",
    "\n",
    "### Multithreading is very simple and you should probably use it\n",
    "\n",
    "### Magic Numbers"
   ],
   "id": "9cbdf7bb84f28a3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why you (probably) don't need more than one GPU\n",
    "\n",
    "### Large Model? Use Quantization\n",
    "\n",
    "### Training (generally) doesn't scale well to multiple GPUs\n",
    "\n"
   ],
   "id": "d35812a242da8c42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Some more specific Tips\n",
    "\n",
    "#### People have probably already implemented a lot of the things you need\n",
    "LINKS HERE\n",
    "Huggingface\n",
    "\n",
    "#### Mixed Precision is cool\n",
    "\n",
    "#### Accelerate is a library that exists\n",
    "\n",
    "#### There are differences in how various kernels handle torch.compile\n"
   ],
   "id": "f1ac5f72dcb12e8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
