{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pytorch Crash Course",
   "id": "d4b1c432bf83343c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quick Tips for installing Pytorch\n",
    "You need the CUDA Toolkit and an Nvidia GPU.\n",
    "\n",
    "Type\n",
    "```\n",
    "nvcc --version\n",
    "```\n",
    "into your console to figure out what CUDA version you have.\n",
    "\n",
    "If you don't get a return on your own computer, you might need to install the [CUDA Toolkit](https://developer.nvidia.com/cuda/toolkit).\n",
    "###### _If you are on a remote computer, you probably can't do that on your own. Talk to an admin instead._\n",
    "\n",
    "If everything is alright the return should look roughly like this:\n",
    "```\n",
    "nvcc: NVIDIA (R) Cuda compiler driver\n",
    "Copyright (c) 2005-2024 NVIDIA Corporation\n",
    "Built on Wed_Aug_14_10:26:51_Pacific_Daylight_Time_2024\n",
    "Cuda compilation tools, release 12.6, V12.6.68\n",
    "Build cuda_12.6.r12.6/compiler.34714021_0\n",
    "```\n",
    "(I have CUDA 12.6 on the machine I ran the command)\n",
    "\n",
    "Now you can go to [pytorch's official website](pytroch.org) to download pytorch for the correct CUDA version.\n",
    "\n",
    "Pytorch seems to be okay at dealing with CUDA version mismatches, I have seen newer versions of pytorch run fine with older CUDA versions. __DON'T QUOTE ME ON THIS THOUGH__\n",
    "\n",
    "Pytorch also offers [old versions](https://pytorch.org/get-started/previous-versions/) for download, which work with older CUDA versions.\n",
    "\n"
   ],
   "id": "9159a1dd2c6dca9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why Pytorch?\n",
    "\n",
    "- Differentiation is hard, PyTorch does it for you with one line of code\n",
    "- Implementing"
   ],
   "id": "8435c3786c6b6ae7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why use GPUs for Machine Learning?\n",
    "\n",
    "#### A Demo:\n",
    "Let's fit a CNN to CIFAR10.\n",
    "(_This code is shamelessly copied from an exercise in Prof. Jain's FMI course from last year_)"
   ],
   "id": "4cdc649c457ebf50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:43:21.956839968Z",
     "start_time": "2026-01-18T12:43:21.945444167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "in_channels   = 3\n",
    "num_classes   = 10\n",
    "num_workers   = 8\n",
    "batch_size    = 256 #this is pretty large for the actual model we use here, but not unreasonable in other usecases\n",
    "num_epochs    = 15\n",
    "learning_rate = 0.005"
   ],
   "id": "93eeda98c1fbfdb8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:28:09.591938992Z",
     "start_time": "2026-01-18T12:28:08.257868610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_data = datasets.CIFAR10(root='data', train=True, transform=transform,download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")"
   ],
   "id": "6cc54032965b6ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:28:11.655586432Z",
     "start_time": "2026-01-18T12:28:11.638774885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout2d(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 5 * 5, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "b67ea269f184059a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T22:01:39.490141848Z",
     "start_time": "2026-01-16T21:59:49.213082871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        z = model(X)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "e9ac4e5267f1e9b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:50<00:00,  7.35s/it]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T22:02:05.332697593Z",
     "start_time": "2026-01-16T22:01:39.513312736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        z = model(X)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "d1cb456a09bac34c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:25<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Wow, the Code that runs almost a minute faster on my GPU (And it will run even faster after we have optimized it later). How can that be? #TODO: ACTUAL TIME\n",
    "\n",
    "Long story short: Forward- and backward-passes (Inference and Training) require massive amounts of vector/matrix (tensor) operations, which are highly parallelizable. GPUs (Graphics Processing Units) are built to solve these kinds of highly parallel operations to render pretty computer graphics, so they are also good at neural networks by accident. Datacenter GPUs nowadays are often purpose built for ML tasks, so they are even better.\n",
    "\n",
    "If you do projects on your home computer and have a decent gaming GPU, then you can probably use it for ML."
   ],
   "id": "80f2302998de3ebc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Okay but how do I PyTorch?\n",
    "\n",
    "#### Online Resources\n",
    "- [Official Documentation](https://docs.pytorch.org/docs/stable/index.html): For looking up syntax etc.\n",
    "- [Official Tutorials](https://docs.pytorch.org/tutorials/index.html): This is the best place to start; also teaches a lot of general ML things.\n",
    "- [Huggingface Tutorials](https://huggingface.co/learn): If you are specifically interested in NLP, then this will teach you just enough PyTorch to get by (while also teaching you a lot of other things).\n",
    "- [\"Let's build GPT: from scratch, in code, spelled out.\" by Andrej Karpathy](https://www.youtube.com/watch?v=kCc8FmEb1nY): Not just for people interested in transformers! An excellent tutorial on working with PyTorch to build a complex model. If you are interested also look at [the follow up video on reproducing GPT-2](https://www.youtube.com/watch?v=l8pRSuU81PU)\n",
    "\n",
    "\n",
    "### You already know a lot of the syntax if you know Numpy...\n",
    "\n",
    "- PyTorch tensors represent n-dimensional arrays of various datatypes (just like ndarrays in numpy).\n",
    "- Doing linear Algebra with PyTorch is very similar to doing it with numpy.\n",
    "- A lot of numpy functions are named identically in PyTorch. (so just trying out what you would do in numpy often works)\n",
    "- Most of the ones that aren't identical have an equivalent you can find with a google search.\n",
    "\n"
   ],
   "id": "5700a9e270521bdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:55:18.335114733Z",
     "start_time": "2026-01-18T12:55:18.322889160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_tensor = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "my_tensor"
   ],
   "id": "145a7132926f14cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:55:21.919499455Z",
     "start_time": "2026-01-18T12:55:21.909142250Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor[1][1:]",
   "id": "875836e7d5baad89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:55:22.905071074Z",
     "start_time": "2026-01-18T12:55:22.893544951Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor.reshape((3,2))",
   "id": "1e2e3f041ffba89d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:55:24.601138020Z",
     "start_time": "2026-01-18T12:55:24.589263422Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor * 2",
   "id": "e4915927e1a95872",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:55:55.099858547Z",
     "start_time": "2026-01-18T12:55:55.087290818Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor.T",
   "id": "f9f8c9221997b375",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:56:29.218572860Z",
     "start_time": "2026-01-18T12:56:29.206677891Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor.unsqueeze(0)",
   "id": "1b599463ea886271",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:57:31.906452669Z",
     "start_time": "2026-01-18T12:57:31.893029387Z"
    }
   },
   "cell_type": "code",
   "source": "my_tensor @ my_tensor.T #matrix multiplication",
   "id": "cc6eec695a3afd4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### The important new bit: The GPU\n",
    "Tensors need to explicitly be moved between devices."
   ],
   "id": "c2cc964aa7143204"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:48:26.871107541Z",
     "start_time": "2026-01-18T12:48:26.858883565Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available() #check if GPU is available",
   "id": "6e2ff99e29381227",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:52:32.176546951Z",
     "start_time": "2026-01-18T12:52:32.164968230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_second_tensor = torch.tensor([[4, 5, 6],[7, 8, 9]])\n",
    "my_second_tensor.device"
   ],
   "id": "15c96df50ae9897",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:52:35.304893416Z",
     "start_time": "2026-01-18T12:52:35.291785382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_second_tensor = my_second_tensor.to(\"cuda\")\n",
    "my_second_tensor.device"
   ],
   "id": "a6a73656409c991f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:53:09.420500214Z",
     "start_time": "2026-01-18T12:53:09.388802914Z"
    }
   },
   "cell_type": "code",
   "source": "print(my_tensor + my_second_tensor)",
   "id": "d4786d8b93eba300",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmy_tensor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmy_second_tensor\u001B[49m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:53:10.443739558Z",
     "start_time": "2026-01-18T12:53:10.433016369Z"
    }
   },
   "cell_type": "code",
   "source": "print(my_tensor.to(\"cuda\") + my_second_tensor)",
   "id": "de5b8121caa263f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7,  9],\n",
      "        [11, 13, 15]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ... and most of numpy is just translating mathematical operations into code.\n",
    "Which means that\n",
    "\n",
    "- If you are implementing a paper, as a first step, implement the tensor operations exactly as described using torch, then start thinking about how to improve performance.\n",
    "- If you are starting from scratch, take a minute or two to write down what you want to implement in mathematical notation first.\n",
    "- A good trick to ensure consistency is to use variable names that match the mathematical symbols.\n",
    "- Don't forget that a lot of popular papers will already have implementations, using them (even if just as a reference) makes your life easier.\n",
    "\n",
    "##### An Example:\n",
    "\n",
    "This is the loss function (clipped surrogate objective) from the [DPO Paper](https://arxiv.org/pdf/2305.18290) (\"Direct Preference Optimization:\n",
    "Your Language Model is Secretly a Reward Model\", Rafailov et al. 2024)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{DPO}(\\pi_{\\theta};\\pi_{ref})=-\\mathbb{E}_{(x,y_w,y_l)\\sim\\mathcal{D}} \\left[ \\sigma \\left(\\beta\\log\\frac{\\pi_{\\theta}(y_w | x)}{\\pi_{ref}(y_w | x)}  -\\beta\\log\\frac{\\pi_{\\theta}(y_l | x)}{\\pi_{ref}(y_l | x)}\\right) \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "```python\n",
    "L_DPO = - torch.mean(torch.nn.sigmoid(beta * torch.log(pi_theta_winner / pi_ref_winner) - beta * torch.log(pi_theta_loser / pi_ref_loser)))\n",
    "```\n",
    "\n",
    "at which point you just need to write something like\n",
    "```\n",
    "optimizer.zero_grad()\n",
    "L_DPO.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "to almost have a trainable model."
   ],
   "id": "2a74e101ee1f3dad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### You probably want to use nn.Module to create your models\n",
    "\n",
    "A super easy way to test out your own neural network architectures is to use nn.Module. TODO\n"
   ],
   "id": "dd1249eaeadc1126"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# A sample model with",
   "id": "1bf5a71df1d512f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Handling Datasets\n",
    "- Having your data stored in memory can be a good or a bad idea\n",
    "- dataloader asynchronous stuff"
   ],
   "id": "eff8463c64f9930c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:28:30.771103334Z",
     "start_time": "2026-01-18T12:28:30.758586105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(device):\n",
    "    train_data_raw = datasets.CIFAR10(\n",
    "        root='data',\n",
    "        train=True,\n",
    "        download=True\n",
    "    )\n",
    "    train_x = torch.tensor(train_data_raw.data, device=device, dtype=torch.float32)\n",
    "    train_y = torch.tensor(train_data_raw.targets, device=device)\n",
    "    norm = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    train_x = norm(torch.transpose(train_x,-1,-3))\n",
    "    return (train_x, train_y)"
   ],
   "id": "f1e9377628ebd2d2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:39:41.956759914Z",
     "start_time": "2026-01-18T12:39:33.157527467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "\n",
    "\n",
    "X,y = get_data(device)\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        z = model(X[i:i + batch_size])\n",
    "        loss = F.cross_entropy(z, y[i:i + batch_size])\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()"
   ],
   "id": "dc35a2cd4fb7c338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "nn.Modulelist if you need to iterate through modules!!!! this is particularly import for compile (see below)",
   "id": "2a57d268d595352"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## How to write Pytorch Code that isn't (too) bad\n",
    "\n",
    "This is a guide to avoiding some common pitfalls, not to writing the fastest code possible (you probably wouldn't have time for that anyway).\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "- Compute is an expensive shared resource.\n",
    "- Wasting compute means literally just creating entropy (CLIMATE CHANGE IS A THING).\n",
    "- Other people also have projects they want to do.\n",
    "\n",
    "#### Some Online Guides that go more in-depth"
   ],
   "id": "41be8babb141ec4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "72b6078b8ccbac91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Enable Tensor Cores (if applicable)\n",
    "\n",
    "Your GPU might not support this (Nvidia GPUs for datacenters like KIGS or the HPC in Erlangen do). Most libraries that implements models (e.g. transformers etc.) will either do this by default or let you enable it through them.\n",
    "\n",
    "Reduce length of Mantissa in 32-bit floating point numbers from 23 to 10 (TensorFloat-32) or 7 (bfloat16) while keeping exponent length the same to preserve range of values."
   ],
   "id": "f224c2330d59cdcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:38:52.249478002Z",
     "start_time": "2026-01-18T12:38:52.236135271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.set_float32_matmul_precision('high') #TF32\n",
    "torch.set_float32_matmul_precision('medium') #BF16\n",
    "\n",
    "def train(model, optimizer, x, y):\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        z = model(x)\n",
    "        loss = F.cross_entropy(z, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ],
   "id": "b6ef2342b0119ebc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "WHAT IS A TENSOR CORE\n",
    "\n",
    "\n",
    "### torch.compile is really neat\n",
    "\n",
    "You might need to install Triton though. It can usually be installed like any python package. [Windows version](https://github.com/woct0rdho/triton-windows) also exists now.\n"
   ],
   "id": "5165ac05db384678"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:39:09.622080842Z",
     "start_time": "2026-01-18T12:38:53.183180159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "X,y = get_data(device)\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "train = torch.compile(train)\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        train(model, optimizer, X[i:i + batch_size], y[i:i + batch_size])\n",
    "\n",
    "    torch.cuda.synchronize()\n"
   ],
   "id": "c407e978aa672452",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s][2026-01-18 12:38:54,658] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2026-01-18 12:38:57,222] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "100%|██████████| 15/15 [00:15<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for inference you can compile you model, for training it's best practice to compile a train function instead\n",
    "\n",
    "reduce overhead arg can help with small models/batches (try it out in each usecase)\n",
    "\n",
    "avoid graph breaks; no non pytorch stuff in compile\n",
    "\n",
    "best practices: avoid inplace ops when possible, AOTAutograd sometimes has issues with them\n"
   ],
   "id": "ca443b9b8f7ffb33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### The CPU-GPU Bottleneck\n",
    "\n"
   ],
   "id": "566a46c0efe9bf22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T22:03:58.840773663Z",
     "start_time": "2026-01-16T22:03:39.719559393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "X,y = get_data(device)\n",
    "\n",
    "model = Net(num_classes)\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    for i in range(0, X.size(0), batch_size):\n",
    "        z = model(X[i:i + batch_size])\n",
    "        a = int(X[0][0][0][0])\n",
    "        loss = F.cross_entropy(z, y[i:i + batch_size])\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ],
   "id": "53596af2e22971ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s][2026-01-16 22:03:41,094] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2026-01-16 22:03:43,181] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      " 20%|██        | 30/150 [00:18<01:12,  1.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(z, y[i:i \u001B[38;5;241m+\u001B[39m batch_size])\n\u001B[1;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/PycharmProjects/DIS/.venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/DIS/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Views and Copies\n",
    "\n",
    "### Multithreading is very simple and you should probably use it\n",
    "\n",
    "- example: pipeline processing image timeseries:\n",
    "\t- real world usecase: sequential steps, process as fast as possible\n",
    "\t- naive training approach follows same logic: proprocessing first step on cpu, cnn on first frame, first rnn step, proprocessing second step, cnn on second frame, seocnd rnn step\n",
    "\t- batch cnn step, multithread, avoid idle gpu time\n",
    "\t- THIS  IS OBVIOUS WHEN YOU THINK ABOUT IT, but pytorch makes it easy to not do it\n",
    "\t- you can use normal multithreading for standard python code\n",
    "\n",
    "### Magic Numbers\n",
    "\n",
    "### Avoiding Computation of Unnecessary Gradients"
   ],
   "id": "9cbdf7bb84f28a3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why you (probably) don't need more than one GPU\n",
    "\n",
    "### Large Model? Use Quantization\n",
    "\n",
    "### Training (generally) doesn't scale well to multiple GPUs\n",
    "\n"
   ],
   "id": "d35812a242da8c42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Some more specific Tips\n",
    "\n",
    "#### People have probably already implemented a lot of the things you need\n",
    "LINKS HERE\n",
    "Huggingface\n",
    "\n",
    "#### Mixed Precision is cool\n",
    "\n",
    "#### Accelerate is a library that exists\n",
    "\n",
    "#### There are differences in how various kernels handle torch.compile\n"
   ],
   "id": "f1ac5f72dcb12e8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
